{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import  RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the pdf\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data, \n",
    "                             glob=\"*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf('/Users/visakh/Desktop/Gen_AI/medical_chat_bot/Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Create text chunks \n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=30)\n",
    "    text_chunk = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40090"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: chromadb\n",
      "Version: 0.6.3\n",
      "Summary: Chroma.\n",
      "Home-page: https://github.com/chroma-core/chroma\n",
      "Author: \n",
      "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
      "License: \n",
      "Location: /Users/visakh/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages\n",
      "Requires: bcrypt, build, chroma-hnswlib, fastapi, grpcio, httpx, importlib-resources, kubernetes, mmh3, numpy, onnxruntime, opentelemetry-api, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, opentelemetry-sdk, orjson, overrides, posthog, pydantic, pypika, PyYAML, rich, tenacity, tokenizers, tqdm, typer, typing_extensions, uvicorn\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"medical_chat_bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\"\n",
    "    ],\n",
    "    ids=[\"id1\", \"id2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m documents = [chunk.page_content \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks]\n\u001b[32m      2\u001b[39m ids = [\u001b[38;5;28mstr\u001b[39m(uuid.uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/chromadb/api/models/Collection.py:82\u001b[39m, in \u001b[36mCollection.add\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     49\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     60\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     61\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \n\u001b[32m     80\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     add_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._add(\n\u001b[32m     92\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m     93\u001b[39m         ids=add_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    100\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:90\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     92\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:213\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_add_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    212\u001b[39m     validate_record_set_for_embedding(record_set=add_records)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     add_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     add_embeddings = add_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:526\u001b[39m, in \u001b[36mCollectionCommon._embed_record_set\u001b[39m\u001b[34m(self, record_set, embeddable_fields)\u001b[39m\n\u001b[32m    522\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed(\n\u001b[32m    523\u001b[39m                 \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28mself\u001b[39m._data_loader(uris=cast(URIs, record_set[field]))  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    524\u001b[39m             )\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    528\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    530\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:539\u001b[39m, in \u001b[36mCollectionCommon._embed\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    536\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.trychroma.com/guides/embeddings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/chromadb/api/types.py:466\u001b[39m, in \u001b[36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) -> Embeddings:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(cast(Embeddings, normalize_embeddings(result)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/chromadb/utils/embedding_functions/onnx_mini_lm_l6_v2.py:200\u001b[39m, in \u001b[36mONNXMiniLM_L6_V2.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Documents) -> Embeddings:\n\u001b[32m    198\u001b[39m     \u001b[38;5;66;03m# Only download the model when it is actually used\u001b[39;00m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28mself\u001b[39m._download_model_if_not_exists()\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Embeddings, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/chromadb/utils/embedding_functions/onnx_mini_lm_l6_v2.py:143\u001b[39m, in \u001b[36mONNXMiniLM_L6_V2._forward\u001b[39m\u001b[34m(self, documents, batch_size)\u001b[39m\n\u001b[32m    134\u001b[39m attention_mask = np.array([e.attention_mask \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m encoded])\n\u001b[32m    135\u001b[39m onnx_input = {\n\u001b[32m    136\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m: np.array(input_ids, dtype=np.int64),\n\u001b[32m    137\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m: np.array(attention_mask, dtype=np.int64),\n\u001b[32m   (...)\u001b[39m\u001b[32m    141\u001b[39m     ),\n\u001b[32m    142\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m model_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnx_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m last_hidden_state = model_output[\u001b[32m0\u001b[39m]\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# Perform mean pooling with attention weighting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gen_AI/medical_chat_bot/.env/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:270\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, output_names, input_feed, run_options)\u001b[39m\n\u001b[32m    268\u001b[39m     output_names = [output.name \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._outputs_meta]\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m C.EPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_fallback:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "documents = [chunk.page_content for chunk in text_chunks]\n",
    "ids = [str(uuid.uuid4()) for _ in documents]\n",
    "\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id1', 'id2']], 'embeddings': None, 'documents': [['This is a document about pineapple', 'This is a document about oranges']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[1.0403752326965332, 1.2430689334869385]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    " \n",
    "results = collection.query(\n",
    "    query_texts=[\"This is a query document about hawaii\"], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
